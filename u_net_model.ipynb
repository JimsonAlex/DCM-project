{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataLoader(Sequence):\n",
    "    def __init__(self, image_paths, mask_paths, batch_size=32, image_size=(256, 256), shuffle=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.image_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch.\"\"\"\n",
    "        return int(np.floor(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data.\"\"\"\n",
    "        batch_indices = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        \n",
    "        batch_images = [self.load_image(self.image_paths[i]) for i in batch_indices]\n",
    "        batch_masks = [self.load_mask(self.mask_paths[i]) for i in batch_indices]\n",
    "        \n",
    "        batch_images = np.array(batch_images) / 255.0  # Normalize image pixel values to [0, 1]\n",
    "        batch_masks = np.array(batch_masks)  # Masks should be binary\n",
    "        \n",
    "        return batch_images, batch_masks\n",
    "\n",
    "    def load_image(self, path):\n",
    "        \"\"\"Load and preprocess an image.\"\"\"\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.resize(image, self.image_size)  # Resize to (256, 256)\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, path):\n",
    "        \"\"\"Load and preprocess a mask.\"\"\"\n",
    "        mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  # Read in grayscale (single channel)\n",
    "        mask = cv2.resize(mask, self.image_size)  # Resize to (256, 256)\n",
    "        mask = mask.astype(np.float32)  # Convert mask to float32\n",
    "        mask = mask / 255.0  # Normalize to [0, 1]\n",
    "        return mask\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Shuffle the data at the end of each epoch.\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_unet(input_size=(256, 256, 3)):\n",
    "    inputs = layers.Input(input_size)\n",
    "\n",
    "    # Encoder (Contracting Path)\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D((2, 2))(conv3)\n",
    "\n",
    "    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = layers.MaxPooling2D((2, 2))(conv4)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Decoder (Expansive Path)\n",
    "    up6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "    concat6 = layers.concatenate([up6, conv4], axis=-1)\n",
    "    conv6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(concat6)\n",
    "    conv6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    concat7 = layers.concatenate([up7, conv3], axis=-1)\n",
    "    conv7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(concat7)\n",
    "    conv7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "    concat8 = layers.concatenate([up8, conv2], axis=-1)\n",
    "    conv8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(concat8)\n",
    "    conv8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "    concat9 = layers.concatenate([up9, conv1], axis=-1)\n",
    "    conv9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(concat9)\n",
    "    conv9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    # Output layer (single channel binary mask)\n",
    "    output = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model(inputs, output)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naomimalange/miniconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6287s\u001b[0m 34s/step - accuracy: 0.9092 - loss: 0.2706\n",
      "Epoch 2/10\n",
      "\u001b[1m 10/187\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:01:47\u001b[0m 41s/step - accuracy: 0.9667 - loss: 0.0780"
     ]
    }
   ],
   "source": [
    "\n",
    "image_folder = '/Users/naomimalange/Desktop/M1/AI Lab/Ongoing projects/DCM/resized_images'\n",
    "mask_folder = '/Users/naomimalange/Desktop/M1/AI Lab/Ongoing projects/DCM/resized_masks'\n",
    "\n",
    "# Collect all image and mask paths\n",
    "image_paths = [os.path.join(image_folder, fname) for fname in os.listdir(image_folder) if fname.endswith('.png')]\n",
    "mask_paths = [os.path.join(mask_folder, fname) for fname in os.listdir(mask_folder) if fname.endswith('.png')]\n",
    "\n",
    "\n",
    "image_paths.sort()\n",
    "mask_paths.sort()\n",
    "\n",
    "batch_size = 16\n",
    "image_size = (256, 256)  \n",
    "\n",
    "data_loader = DataLoader(image_paths, mask_paths, batch_size=batch_size, image_size=image_size)\n",
    "\n",
    "unet_model = build_unet(input_size=(256, 256, 3))\n",
    "\n",
    "\n",
    "unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "unet_model.fit(data_loader, epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
